{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8898e6",
   "metadata": {},
   "source": [
    "# Reproduce results of trained CNN & CNN-Attention models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f9165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample: 19952\n",
      "dev sample: 1050\n",
      "test sample: 1105\n",
      "Counter({'non-opinion': 11746, 'opinion': 8206})\n",
      "Counter({'non-opinion': 612, 'opinion': 438})\n",
      "Counter({'non-opinion': 642, 'opinion': 463})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 09:43:09,567 [DEBUG] kashgari - ------------------------------------------------\n",
      "2022-06-22 09:43:09,568 [DEBUG] kashgari - Loaded gensim word2vec model's vocab\n",
      "2022-06-22 09:43:09,568 [DEBUG] kashgari - model        : mat_embedding3/vectors.txt\n",
      "2022-06-22 09:43:09,569 [DEBUG] kashgari - word count   : 529690\n",
      "2022-06-22 09:43:09,569 [DEBUG] kashgari - Top 50 words : ['the', 'of', '.', ',', 'and', '<nUm>', 'in', 'a', 'to', ')', '(', 'with', '-', 'for', 'is', 'by', 'on', 'was', 'at', 'were', 'that', '–', 'as', 'are', 'from', '/', 'an', 'temperature', 'surface', 'using', 'high', 'which', 'C', '°', 'this', '%', 'In', 'it', 'A', '=', 'structure', 'properties', ':', 'phase', 'results', 'effect', 'these', 'than', 'based', 'different']\n",
      "2022-06-22 09:43:09,569 [DEBUG] kashgari - ------------------------------------------------\n",
      "2022-06-22 09:43:10,976 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 282\n",
      "2022-06-22 09:43:10,993 [DEBUG] kashgari - predict input shape (1105, 282) x: \n",
      "[[   0    1    1 ...    0    0    0]\n",
      " [   0    1 3255 ...    0    0    0]\n",
      " [   0   13    7 ...    0    0    0]\n",
      " ...\n",
      " [   0    1 4751 ...    0    0    0]\n",
      " [   0    1  401 ...    0    0    0]\n",
      " [   0    1  163 ...    0    0    0]]\n",
      "2022-06-22 09:43:11,440 [DEBUG] kashgari - predict output shape (1105, 2)\n",
      "2022-06-22 09:43:11,442 [DEBUG] kashgari - predict output argmax: [1 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-opinion     0.9446    0.9564    0.9505       642\n",
      "     opinion     0.9385    0.9222    0.9303       463\n",
      "\n",
      "    accuracy                         0.9421      1105\n",
      "   macro avg     0.9415    0.9393    0.9404      1105\n",
      "weighted avg     0.9420    0.9421    0.9420      1105\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'non-opinion': {'precision': 0.9446153846153846,\n",
       "   'recall': 0.956386292834891,\n",
       "   'f1-score': 0.9504643962848297,\n",
       "   'support': 642},\n",
       "  'opinion': {'precision': 0.9384615384615385,\n",
       "   'recall': 0.9222462203023758,\n",
       "   'f1-score': 0.9302832244008714,\n",
       "   'support': 463},\n",
       "  'accuracy': 0.9420814479638009,\n",
       "  'macro avg': {'precision': 0.9415384615384615,\n",
       "   'recall': 0.9393162565686334,\n",
       "   'f1-score': 0.9403738103428505,\n",
       "   'support': 1105},\n",
       "  'weighted avg': {'precision': 0.9420368952314654,\n",
       "   'recall': 0.9420814479638009,\n",
       "   'f1-score': 0.9420083939479313,\n",
       "   'support': 1105}},\n",
       " 'precision': 0.9420368952314654,\n",
       " 'recall': 0.9420814479638009,\n",
       " 'f1-score': 0.9420083939479313,\n",
       " 'support': 1105}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kashgari\n",
    "from kashgari.tasks.classification import CNN_Attention_Model, CNN_Model\n",
    "\n",
    "# load mixed-topic dataset with opinion/non-opinion annotation\n",
    "with open('data/3_in_1/cnn_x.json', 'r', encoding='utf-8') as f:\n",
    "    store_x = json.load(f)\n",
    "with open('data/3_in_1/cnn_y.json', 'r', encoding='utf-8') as f:\n",
    "    store_y = json.load(f)\n",
    "with open('data/3_in_1/testcnn_x.json', 'r', encoding='utf-8') as f:\n",
    "    test_x = json.load(f)\n",
    "with open('data/3_in_1/testcnn_y.json', 'r', encoding='utf-8') as f:\n",
    "    test_y = json.load(f)  \n",
    "\n",
    "# split train & dev set\n",
    "valid_x, train_x, valid_y, train_y = train_test_split(store_x, store_y, test_size=0.95, random_state=42)\n",
    "\n",
    "print(f\"train sample: {len(train_x)}\")\n",
    "print(f\"dev sample: {len(valid_x)}\")\n",
    "print(f\"test sample: {len(test_x)}\")\n",
    "print(Counter(train_y))\n",
    "print(Counter(valid_y))\n",
    "print(Counter(test_y))\n",
    "\n",
    "load_CNN = CNN_Model.load_model('data/CNN_94_95_93')\n",
    "load_CNN.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4ceffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample: 9224\n",
      "dev sample: 912\n",
      "test sample: 950\n",
      "Counter({'driver': 6337, 'barrier': 2887})\n",
      "Counter({'driver': 627, 'barrier': 285})\n",
      "Counter({'driver': 774, 'barrier': 176})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 09:44:50,633 [DEBUG] kashgari - ------------------------------------------------\n",
      "2022-06-22 09:44:50,634 [DEBUG] kashgari - Loaded gensim word2vec model's vocab\n",
      "2022-06-22 09:44:50,634 [DEBUG] kashgari - model        : mat_embedding3/vectors.txt\n",
      "2022-06-22 09:44:50,634 [DEBUG] kashgari - word count   : 529690\n",
      "2022-06-22 09:44:50,635 [DEBUG] kashgari - Top 50 words : ['the', 'of', '.', ',', 'and', '<nUm>', 'in', 'a', 'to', ')', '(', 'with', '-', 'for', 'is', 'by', 'on', 'was', 'at', 'were', 'that', '–', 'as', 'are', 'from', '/', 'an', 'temperature', 'surface', 'using', 'high', 'which', 'C', '°', 'this', '%', 'In', 'it', 'A', '=', 'structure', 'properties', ':', 'phase', 'results', 'effect', 'these', 'than', 'based', 'different']\n",
      "2022-06-22 09:44:50,635 [DEBUG] kashgari - ------------------------------------------------\n",
      "2022-06-22 09:44:52,399 [WARNING] kashgari - Sequence length is None, will use the max length of the samples, which is 171\n",
      "2022-06-22 09:44:52,416 [DEBUG] kashgari - predict input shape (950, 171) x: \n",
      "[[   0    1   18 ...    0    0    0]\n",
      " [   0    1  174 ...    0    0    0]\n",
      " [   0    1  749 ...    0    0    0]\n",
      " ...\n",
      " [   0    1 3322 ...    0    0    0]\n",
      " [   0    1    4 ...    0    0    0]\n",
      " [   0   40  148 ...    0    0    0]]\n",
      "2022-06-22 09:44:53,287 [DEBUG] kashgari - predict output shape (950, 2)\n",
      "2022-06-22 09:44:53,290 [DEBUG] kashgari - predict output argmax: [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     barrier     0.7727    0.7727    0.7727       176\n",
      "      driver     0.9483    0.9483    0.9483       774\n",
      "\n",
      "    accuracy                         0.9158       950\n",
      "   macro avg     0.8605    0.8605    0.8605       950\n",
      "weighted avg     0.9158    0.9158    0.9158       950\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detail': {'barrier': {'precision': 0.7727272727272727,\n",
       "   'recall': 0.7727272727272727,\n",
       "   'f1-score': 0.7727272727272727,\n",
       "   'support': 176},\n",
       "  'driver': {'precision': 0.9483204134366925,\n",
       "   'recall': 0.9483204134366925,\n",
       "   'f1-score': 0.9483204134366925,\n",
       "   'support': 774},\n",
       "  'accuracy': 0.9157894736842105,\n",
       "  'macro avg': {'precision': 0.8605238430819826,\n",
       "   'recall': 0.8605238430819826,\n",
       "   'f1-score': 0.8605238430819826,\n",
       "   'support': 950},\n",
       "  'weighted avg': {'precision': 0.9157894736842105,\n",
       "   'recall': 0.9157894736842105,\n",
       "   'f1-score': 0.9157894736842105,\n",
       "   'support': 950}},\n",
       " 'precision': 0.9157894736842105,\n",
       " 'recall': 0.9157894736842105,\n",
       " 'f1-score': 0.9157894736842105,\n",
       " 'support': 950}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mixed-topic dataset with opportunity(driver)/challenges(barrier) annotation\n",
    "with open('data/3_in_1/cnnatt_x.json', 'r', encoding='utf-8') as f:\n",
    "    x_data = json.load(f)\n",
    "with open('data/3_in_1/cnnatt_y.json', 'r', encoding='utf-8') as f:\n",
    "    y_data = json.load(f)\n",
    "with open('data/3_in_1/testcnnatt_x.json', 'r', encoding='utf-8') as f:\n",
    "    test_x = json.load(f)\n",
    "with open('data/3_in_1/testcnnatt_y.json', 'r', encoding='utf-8') as f:\n",
    "    test_y = json.load(f)\n",
    "    \n",
    "# add augmented data by SMOTE\n",
    "with open('data/3_in_1/augmented_barrier.json') as file_obj:\n",
    "    barrier = json.load(file_obj)\n",
    "    length = len(barrier)\n",
    "    x_data.extend(barrier)\n",
    "    tmp = ['barrier']*length\n",
    "    y_data.extend(tmp)\n",
    "\n",
    "# split train & dev set\n",
    "valid_x, train_x, valid_y, train_y = train_test_split(x_data, y_data, stratify=y_data, test_size=0.91, random_state=42)\n",
    "\n",
    "print(f\"train sample: {len(train_x)}\")\n",
    "print(f\"dev sample: {len(valid_x)}\")\n",
    "print(f\"test sample: {len(test_x)}\")\n",
    "print(Counter(train_y))\n",
    "print(Counter(valid_y))\n",
    "print(Counter(test_y))\n",
    "\n",
    "load_CNN_Attention = CNN_Attention_Model.load_model('data/CNN_Attention_91')\n",
    "load_CNN_Attention.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20fb4b3",
   "metadata": {},
   "source": [
    "# Apply opinion mining to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ab2324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a tiny text sample with opinions\n",
    "with open('data/text.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "359c9990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Owing', 'to', 'the', 'importance', 'of', 'surface', 'passivation', 'to', 'BSi', ',', 'major', 'passivation', 'techniques', 'using', 'SiNx', ',', 'thermal', 'oxide', ',', 'Al2O3', 'and', 'a-Si', 'have', 'been', 'critically', 'examined', '.']\n",
      "['It', 'is', 'found', 'that', 'atomic', 'layer', 'deposited', 'Al2O3', 'offers', 'excellent', 'surface', 'conformality', 'and', 'passivation', 'to', 'the', 'silicon', 'surface', ',', 'especially', 'on', 'p+-emitters', '.']\n",
      "['With', 'ALD', 'Al2O3', 'passivation', ',', 'a', 'record', 'high', '18.7', '%', 'efficient', 'BSi', 'solar', 'cell', 'has', 'been', 'successfully', 'fabricated', '.']\n",
      "['As', 'the', 'market', 'share', 'of', 'n-type', 'solar', 'cells', '(', 'with', 'p+-emitters', ')', 'is', 'expected', 'to', 'rise', 'in', 'the', 'near', 'future', ',', 'this', 'passivation', 'technique', 'is', 'particularly', 'attractive', 'and', 'may', 'become', 'a', 'new', 'industry', 'standard', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk # if no nltk, use split('. ')\n",
    "\n",
    "# 1. segmentation + tokenization\n",
    "def sen_seg(data): \n",
    "    sens = []\n",
    "    to_replace = ['et al. ', 'Fig. ', 'e.g. ', 'i.e. ', 'Ref. ', 'Figs. ', ' ca. ', 'approx. ', '(ca. ', 'etc.) ']\n",
    "    for tr in to_replace:\n",
    "        data = data.replace(tr, tr[:-2]+'####@')\n",
    "    tmp = nltk.sent_tokenize(data)\n",
    "    # tmp = data.split('. ')\n",
    "    for i, t in enumerate(tmp):\n",
    "        for tr in to_replace:\n",
    "            t = t.replace(tr[:-2]+'####@', tr)\n",
    "        tmp[i] = t\n",
    "    for t in tmp:\n",
    "        sens.append(nltk.word_tokenize(t))\n",
    "        # sens.append(t.split(' '))\n",
    "    return sens\n",
    "\n",
    "sens = sen_seg(text)\n",
    "for t in sens:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3075da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 19:22:43,680 [DEBUG] kashgari - predict input shape (4, 37) x: \n",
      "[[    0     1    12     4  1901     5    32  1842    12 26580     7   761\n",
      "   1842   371    33  7117     7   162   166     7   416     8  2050   117\n",
      "   2338 10596   426     6     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     1    18    71    24   474    72   255   416  2770   603    32\n",
      "  45533     8  1842    12     4   293    32     7   766    20     1     6\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     1  3575   416  1842     7    11  2342    34     1    39   621\n",
      "  26580   643   391   136  2338   886   347     6     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0   302     4  5199  7963     5     1   643   589    14    15     1\n",
      "     13    18   785    12  1874    10     4   312  1508     7    38  1842\n",
      "    203    18  1392  2684     8   797  1751    11   126  2916   800     6\n",
      "      0]]\n",
      "2022-06-22 19:22:43,718 [DEBUG] kashgari - predict output shape (4, 2)\n",
      "2022-06-22 19:22:43,718 [DEBUG] kashgari - predict output argmax: [0 1 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 opinions is found by CNN\n",
      "[['It', 'is', 'found', 'that', 'atomic', 'layer', 'deposited', 'Al2O3', 'offers', 'excellent', 'surface', 'conformality', 'and', 'passivation', 'to', 'the', 'silicon', 'surface', ',', 'especially', 'on', 'p+-emitters', '.'], ['As', 'the', 'market', 'share', 'of', 'n-type', 'solar', 'cells', '(', 'with', 'p+-emitters', ')', 'is', 'expected', 'to', 'rise', 'in', 'the', 'near', 'future', ',', 'this', 'passivation', 'technique', 'is', 'particularly', 'attractive', 'and', 'may', 'become', 'a', 'new', 'industry', 'standard', '.']]\n"
     ]
    }
   ],
   "source": [
    "# 2. apply opinion extraction\n",
    "find_opinion = []\n",
    "result = load_CNN.predict(sens)\n",
    "for i, tx in enumerate(sens):\n",
    "    if result[i] == 'opinion':\n",
    "        find_opinion.append(tx)\n",
    "        \n",
    "print(len(find_opinion), 'opinions are found by CNN')\n",
    "print(find_opinion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09589a6d",
   "metadata": {},
   "source": [
    "## Optional corpus comparison method to add/remove opinions to certain ratio\n",
    "### Note: If you don't need this part, just skip it and run next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef57f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many opinions, so rank & remove low score opinion\n",
      "1 opinions found in total by 0.25 * 4\n",
      "[['As', 'the', 'market', 'share', 'of', 'n-type', 'solar', 'cells', '(', 'with', 'p+-emitters', ')', 'is', 'expected', 'to', 'rise', 'in', 'the', 'near', 'future', ',', 'this', 'passivation', 'technique', 'is', 'particularly', 'attractive', 'and', 'may', 'become', 'a', 'new', 'industry', 'standard', '.']]\n"
     ]
    }
   ],
   "source": [
    "# optional function: corpus comparison to adjust number of opinions\n",
    "def rank_opinion_by_lexicon(sens, lexicon_file):\n",
    "    words_md = ['could', 'may', 'would', 'must', 'might', 'shall', 'ought', 'can']\n",
    "    score_dic = {}\n",
    "    with open(lexicon_file) as file_obj:\n",
    "        pri_list = json.load(file_obj)\n",
    "    for i, s in enumerate(sens):\n",
    "        score = 0\n",
    "        for ss in s:\n",
    "            if ss.lower() in pri_list or ss in pri_list:\n",
    "                score += 1\n",
    "            if ss.lower() in words_md:\n",
    "                score += 2\n",
    "        score_dic[i] = score\n",
    "    \n",
    "    sorted_dic = sorted(score_dic.items(), key=lambda item:item[1], reverse=True)\n",
    "    rank_opinion = []\n",
    "    for sd in sorted_dic:\n",
    "        rank_opinion.append(sens[sd[0]])\n",
    "    return rank_opinion\n",
    "\n",
    "\n",
    "RATE = 0.25 # a threshold which can be set by user, if whole page, 0.1-0.2 is rather suitable\n",
    "support_opinion = rank_opinion_by_lexicon(sens, 'data/final_200.json')\n",
    "need_length = int(RATE * len(sens))\n",
    "count = 0\n",
    "tmp = []\n",
    "if len(find_opinion) >= need_length:\n",
    "    print('Too many opinions, so rank & remove low score opinion')\n",
    "    for so in support_opinion:\n",
    "        if so in find_opinion:\n",
    "            tmp.append(so)\n",
    "            if len(tmp)==need_length:\n",
    "                break\n",
    "else: \n",
    "    print('Too few opinions, add high score candidate')\n",
    "    rest = [x for x in support_opinion if x not in find_opinion]\n",
    "    tmp.extend(find_opinion)\n",
    "    tmp.extend(rest[:need_length-len(find_opinion)])\n",
    "\n",
    "find_opinion = tmp\n",
    "        \n",
    "print(len(find_opinion), 'opinions found in total by', RATE, '*', str(len(sens)))\n",
    "print(find_opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "090655c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 19:30:17,263 [DEBUG] kashgari - predict input shape (1, 37) x: \n",
      "[[   0  302    4 5199 7963    5    1  643  589   14   15    1   13   18\n",
      "   785   12 1874   10    4  312 1508    7   38 1842  203   18 1392 2684\n",
      "     8  797 1751   11  126 2916  800    6    0]]\n",
      "2022-06-22 19:30:17,305 [DEBUG] kashgari - predict output shape (1, 2)\n",
      "2022-06-22 19:30:17,305 [DEBUG] kashgari - predict output argmax: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 opportunities are found by CNN-Attention.\n",
      "As the market share of n-type solar cells ( with p+-emitters ) is expected to rise in the near future , this passivation technique is particularly attractive and may become a new industry standard .\n",
      "\n",
      "\n",
      "0 challenges are found by CNN-Attention.\n"
     ]
    }
   ],
   "source": [
    "# 2. apply opinion classification\n",
    "find_opps = []\n",
    "find_chas = []\n",
    "result = load_CNN_Attention.predict(find_opinion)\n",
    "for i, tx in enumerate(find_opinion):\n",
    "    if result[i] == 'driver':\n",
    "        find_opps.append(tx)\n",
    "    else:\n",
    "        find_chas.append(tx)\n",
    "        \n",
    "print(len(find_opps), 'opportunities are found by CNN-Attention.')\n",
    "for fo in find_opps:\n",
    "    print(' '.join(fo))\n",
    "print('\\n')\n",
    "print(len(find_chas), 'challenges are found by CNN-Attention.')\n",
    "for fc in find_chas:\n",
    "    print(' '.join(fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466da14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
